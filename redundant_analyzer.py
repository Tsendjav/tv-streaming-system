#!/usr/bin/env python3
"""
–®—É—É—Ä—Ö–∞–π –∏–ª“Ø“Ø–¥—ç–ª —Ñ–∞–π–ª –æ–ª–æ—Ö —Å–∫—Ä–∏–ø—Ç
–¢–∞–Ω—ã tv_streaming_system —Ç”©—Å–ª–∏–π–Ω —Ö–∞–≤—Ç—Å–∞–Ω–¥ —Ö–∞–¥–≥–∞–ª–∂ –∞–∂–∏–ª–ª—É—É–ª–Ω–∞ —É—É
"""
import os
import ast
import json
from pathlib import Path
from datetime import datetime

class RedundantCodeAnalyzer:
    def __init__(self, project_root="."):
        self.project_root = Path(project_root)
        self.imports_map = {}
        self.file_usage = {}
        
    def analyze_imports(self):
        """–ë“Ø—Ö Python —Ñ–∞–π–ª—É—É–¥—ã–Ω import-—É—É–¥—ã–≥ —à–∏–Ω–∂–∏–ª–Ω—ç"""
        print("üîç Import-—É—É–¥—ã–≥ —à–∏–Ω–∂–∏–ª–∂ –±–∞–π–Ω–∞...")
        
        python_files = list(self.project_root.rglob("*.py"))
        
        for file_path in python_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # AST –∞—à–∏–≥–ª–∞–Ω import-—É—É–¥—ã–≥ –æ–ª–æ—Ö
                tree = ast.parse(content)
                imports = []
                
                for node in ast.walk(tree):
                    if isinstance(node, ast.Import):
                        for alias in node.names:
                            imports.append(alias.name)
                    elif isinstance(node, ast.ImportFrom):
                        if node.module:
                            imports.append(node.module)
                
                self.imports_map[str(file_path)] = imports
                
            except Exception as e:
                print(f"‚ö†Ô∏è –ê–ª–¥–∞–∞ {file_path}: {e}")
        
        print(f"‚úÖ {len(python_files)} —Ñ–∞–π–ª—ã–≥ —à–∏–Ω–∂–∏–ª–∂ –¥—É—É—Å–∞–≤")
    
    def find_backup_files(self):
        """Backup —Ñ–∞–π–ª—É—É–¥—ã–≥ –æ–ª–æ—Ö"""
        backup_patterns = [
            "*.backup",
            "*.corrupted", 
            "*_backup_*",
            "main.py.backup",
            "migration_*"
        ]
        
        backup_files = []
        for pattern in backup_patterns:
            backup_files.extend(self.project_root.rglob(pattern))
        
        return backup_files
    
    def find_test_files(self):
        """–¢–µ—Å—Ç —Ñ–∞–π–ª—É—É–¥—ã–≥ –æ–ª–æ—Ö"""
        test_patterns = [
            "test_*.py",
            "*_test.py",
            "example*.py",
            "*example*.py"
        ]
        
        test_files = []
        for pattern in test_patterns:
            test_files.extend(self.project_root.rglob(pattern))
        
        return test_files
    
    def find_duplicate_files(self):
        """–î–∞–≤—Ö–∞—Ä–¥—Å–∞–Ω —Ñ–∞–π–ª—É—É–¥—ã–≥ –æ–ª–æ—Ö"""
        duplicates = []
        
        # Streaming tab —Ñ–∞–π–ª—É—É–¥—ã–≥ —à–∞–ª–≥–∞—Ö
        streaming_files = list(self.project_root.rglob("*streaming_tab*.py"))
        if len(streaming_files) > 1:
            duplicates.extend(streaming_files)
        
        # Main —Ñ–∞–π–ª—É—É–¥—ã–≥ —à–∞–ª–≥–∞—Ö  
        main_files = list(self.project_root.rglob("main*.py"))
        if len(main_files) > 1:
            duplicates.extend(main_files)
            
        return duplicates
    
    def analyze_usage(self):
        """–§–∞–π–ª—É—É–¥—ã–Ω –∞—à–∏–≥–ª–∞–≥–¥–∞–∂ –±–∞–π–≥–∞–∞ –±–∞–π–¥–ª—ã–≥ —à–∞–ª–≥–∞—Ö"""
        print("üîç –§–∞–π–ª—É—É–¥—ã–Ω –∞—à–∏–≥–ª–∞–ª—Ç—ã–≥ —à–∏–Ω–∂–∏–ª–∂ –±–∞–π–Ω–∞...")
        
        # –ë“Ø—Ö –º–æ–¥—É–ª—É—É–¥—ã–≥ –∂–∞–≥—Å–∞–∞—Ö
        all_modules = set()
        for file_path in self.project_root.rglob("*.py"):
            # –§–∞–π–ª—ã–Ω –∑–∞–º—ã–≥ –º–æ–¥—É–ª—ã–Ω –Ω—ç—Ä –±–æ–ª–≥–æ–Ω —Ö—É–≤–∏—Ä–≥–∞—Ö
            rel_path = file_path.relative_to(self.project_root)
            module_name = str(rel_path).replace(os.sep, '.').replace('.py', '')
            all_modules.add(module_name)
        
        # Import —Ö–∏–π–≥–¥—Å—ç–Ω –º–æ–¥—É–ª—É—É–¥—ã–≥ –æ–ª–æ—Ö
        imported_modules = set()
        for imports in self.imports_map.values():
            imported_modules.update(imports)
        
        # –ê—à–∏–≥–ª–∞–≥–¥–∞–∞–≥“Ø–π –º–æ–¥—É–ª—É—É–¥—ã–≥ –æ–ª–æ—Ö
        potentially_unused = []
        for module in all_modules:
            is_used = False
            for imported in imported_modules:
                if module in imported or imported in module:
                    is_used = True
                    break
            
            if not is_used:
                potentially_unused.append(module)
        
        return potentially_unused
    
    def generate_report(self):
        """–ò–ª“Ø“Ø–¥—ç–ª —Ñ–∞–π–ª—É—É–¥—ã–Ω —Ç–∞–π–ª–∞–Ω “Ø“Ø—Å–≥—ç—Ö"""
        print("\nüìä –ò–õ“Æ“Æ–î–≠–õ –§–ê–ô–õ–£–£–î–´–ù –¢–ê–ô–õ–ê–ù")
        print("=" * 50)
        
        # Backup —Ñ–∞–π–ª—É—É–¥
        backup_files = self.find_backup_files()
        print(f"\nüóÇÔ∏è BACKUP –§–ê–ô–õ–£–£–î ({len(backup_files)} –±–∞–π–Ω–∞):")
        for file in backup_files:
            print(f"   üìÑ {file}")
        
        # –¢–µ—Å—Ç —Ñ–∞–π–ª—É—É–¥
        test_files = self.find_test_files()
        print(f"\nüß™ –¢–ï–°–¢ –§–ê–ô–õ–£–£–î ({len(test_files)} –±–∞–π–Ω–∞):")
        for file in test_files:
            print(f"   üìÑ {file}")
        
        # –î–∞–≤—Ö–∞—Ä–¥—Å–∞–Ω —Ñ–∞–π–ª—É—É–¥
        duplicate_files = self.find_duplicate_files()
        print(f"\nüîÑ –î–ê–í–•–ê–†–î–°–ê–ù –§–ê–ô–õ–£–£–î ({len(duplicate_files)} –±–∞–π–Ω–∞):")
        for file in duplicate_files:
            print(f"   üìÑ {file}")
        
        # –ê—à–∏–≥–ª–∞–≥–¥–∞–∞–≥“Ø–π —Ñ–∞–π–ª—É—É–¥
        unused_modules = self.analyze_usage()
        print(f"\n‚ùå –ê–®–ò–ì–õ–ê–ì–î–ê–ê–ì“Æ–ô –§–ê–ô–õ–£–£–î ({len(unused_modules)} –±–∞–π–Ω–∞):")
        for module in unused_modules:
            print(f"   üìÑ {module}")
        
        # –ù–∏–π—Ç –¥“Ø–≥–Ω—ç–ª—Ç
        total_redundant = len(backup_files) + len(test_files) + len(duplicate_files)
        print(f"\nüìà –ù–ò–ô–¢ –î“Æ–ì–ù–≠–õ–¢:")
        print(f"   üóëÔ∏è –ê—é—É–ª–≥“Ø–π —É—Å—Ç–≥–∞–∂ –±–æ–ª–æ—Ö: {total_redundant} —Ñ–∞–π–ª")
        print(f"   ‚ö†Ô∏è –®–∞–ª–≥–∞—Ö —à–∞–∞—Ä–¥–ª–∞–≥–∞—Ç–∞–π: {len(unused_modules)} —Ñ–∞–π–ª")
        
        return {
            'backup_files': [str(f) for f in backup_files],
            'test_files': [str(f) for f in test_files],
            'duplicate_files': [str(f) for f in duplicate_files],
            'unused_modules': unused_modules,
            'total_redundant': total_redundant
        }
    
    def create_cleanup_script(self, report_data):
        """–¶—ç–≤—ç—Ä–ª—ç—Ö —Å–∫—Ä–∏–ø—Ç “Ø“Ø—Å–≥—ç—Ö"""
        script_content = f"""#!/bin/bash
# –ê–≤—Ç–æ–º–∞—Ç “Ø“Ø—Å–≥—ç—Å—ç–Ω —Ü—ç–≤—ç—Ä–ª—ç—Ö —Å–∫—Ä–∏–ø—Ç
# –û–≥–Ω–æ–æ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

echo "üöÄ Backup “Ø“Ø—Å–≥—ç–∂ –±–∞–π–Ω–∞..."
cp -r . ../tv_streaming_system_backup_$(date +%Y%m%d_%H%M%S)

echo "üßπ –ò–ª“Ø“Ø–¥—ç–ª —Ñ–∞–π–ª—É—É–¥—ã–≥ —É—Å—Ç–≥–∞–∂ –±–∞–π–Ω–∞..."

"""
        
        # Backup —Ñ–∞–π–ª—É—É–¥—ã–≥ —É—Å—Ç–≥–∞—Ö
        for file_path in report_data['backup_files']:
            script_content += f'rm -rf "{file_path}"\n'
        
        # –¢–µ—Å—Ç —Ñ–∞–π–ª—É—É–¥—ã–≥ —É—Å—Ç–≥–∞—Ö
        for file_path in report_data['test_files']:
            script_content += f'rm -f "{file_path}"\n'
        
        script_content += '\necho "‚úÖ –¶—ç–≤—ç—Ä–ª—ç–∂ –¥—É—É—Å–∞–≤!"'
        
        # –°–∫—Ä–∏–ø—Ç —Ñ–∞–π–ª–¥ –±–∏—á–∏—Ö
        with open('cleanup_redundant.sh', 'w') as f:
            f.write(script_content)
        
        os.chmod('cleanup_redundant.sh', 0o755)
        print(f"\n‚úÖ –¶—ç–≤—ç—Ä–ª—ç—Ö —Å–∫—Ä–∏–ø—Ç “Ø“Ø—Å–≥—ç–ª—ç—ç: cleanup_redundant.sh")
        print("   –ê–∂–∏–ª–ª—É—É–ª–∞—Ö: ./cleanup_redundant.sh")

def main():
    print("üéØ TV Streaming System - –ò–ª“Ø“Ø–¥—ç–ª –∫–æ–¥ —à–∏–Ω–∂–∏–ª–≥—ç—ç")
    print("=" * 60)
    
    analyzer = RedundantCodeAnalyzer()
    
    # Import-—É—É–¥—ã–≥ —à–∏–Ω–∂–∏–ª—ç—Ö
    analyzer.analyze_imports()
    
    # –¢–∞–π–ª–∞–Ω “Ø“Ø—Å–≥—ç—Ö
    report = analyzer.generate_report()
    
    # JSON —Ç–∞–π–ª–∞–Ω —Ö–∞–¥–≥–∞–ª–∞—Ö
    with open('redundant_code_report.json', 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"\nüíæ –î—ç–ª–≥—ç—Ä—ç–Ω–≥“Ø–π —Ç–∞–π–ª–∞–Ω —Ö–∞–¥–≥–∞–ª–∞–≥–¥–ª–∞–∞: redundant_code_report.json")
    
    # –¶—ç–≤—ç—Ä–ª—ç—Ö —Å–∫—Ä–∏–ø—Ç “Ø“Ø—Å–≥—ç—Ö
    analyzer.create_cleanup_script(report)
    
    print(f"\nüéâ –®–∏–Ω–∂–∏–ª–≥—ç—ç –¥—É—É—Å–∞–≤!")
    print(f"   üí° –ó”©–≤–ª”©–º–∂: –≠—Ö–ª—ç—ç–¥ backup “Ø“Ø—Å–≥—ç—ç–¥ cleanup_redundant.sh –∞–∂–∏–ª–ª—É—É–ª–Ω–∞ —É—É")

if __name__ == "__main__":
    main()